---
---
@article {Tang2023,
  doi = {10.1038/s41467-023-37477-x},
  url = {https://doi.org/10.1038/s41467-023-37477-x},
  year = {2023},
  month = may,
	author = {Tang, Xin and Zhang, Jiawei and He, Yichun and Zhang, Xinhe and Lin, Zuwan and Partarrieu, Sebastian and Bou Hanna, Emma and Ren, Zhaolin and Shen, Hao and Yang, Yuhong and Wang, Xiao and Li, Na and Ding, Jie and Liu, Jia},
	title = {Explainable multi-task learning for multi-modality biological data analysis},
	journal = {Nature Communications},
	html = {https://www.nature.com/articles/s41467-023-37477-x},
  abbr = {Nat. Commun},
  abstract = {Current biotechnologies can simultaneously measure multiple high-dimensional modalities (e.g., RNA, DNA accessibility, and protein) from the same cells. A combination of different analytical tasks (e.g., multi-modal integration and cross-modal analysis) is required to comprehensively understand such data, inferring how gene regulation drives biological diversity and functions. However, current analytical methods are designed to perform a single task, only providing a partial picture of the multi-modal data. Here, we present UnitedNet, an explainable multi-task deep neural network capable of integrating different tasks to analyze single-cell multi-modality data. Applied to various multi-modality datasets (e.g., Patch-seq, multiome ATAC + gene expression, and spatial transcriptomics), UnitedNet demonstrates similar or better accuracy in multi-modal integration and cross-modal prediction compared with state-of-the-art methods. Moreover, by dissecting the trained UnitedNet with the explainable machine learning algorithm, we can directly quantify the relationship between gene expression and other modalities with cell-type specificity. UnitedNet is a comprehensive end-to-end framework that could be broadly applicable to single-cell multi-modality biology. This framework has the potential to facilitate the discovery of cell-type-specific regulation kinetics across transcriptomics and other modalities.}
}

@article{Zhao2023,
  doi = {10.1038/s41593-023-01267-x},
  url = {https://doi.org/10.1038/s41593-023-01267-x},
  year = {2023},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  author = {Siyuan Zhao and Xin Tang and Weiwen Tian and Sebastian Partarrieu and Ren Liu and Hao Shen and Jaeyong Lee and Shiqi Guo and Zuwan Lin and Jia Liu},
  title = {Tracking neural activity from the same cells during the entire adult life of mice},
  journal = {Nature Neuroscience},
  html = {https://www.nature.com/articles/s41593-023-01267-x},
  blog = {https://sebastianpartarrieu.github.io/blog/2023/mesh-electronics-BMI/},
  abbr = {Nat. Neurosci},
  abstract = {Stably recording the electrical activity of the same neurons over the adult life of an animal is important to neuroscience research and biomedical applications. Current implantable devices cannot provide stable recording on this timescale. Here, we introduce a method to precisely implant electronics with an open, unfolded mesh structure across multiple brain regions in the mouse. The open mesh structure forms a stable interwoven structure with the neural network, preventing probe drifting and showing no immune response and neuron loss during the year-long implantation. Rigorous statistical analysis, visual stimulus-dependent measurement and unbiased, machine-learning-based analysis demonstrated that single-unit action potentials have been recorded from the same neurons of behaving mice in a very long-term stable manner. Leveraging this stable structure, we demonstrated that the same neurons can be recorded over the entire adult life of the mouse, revealing the aging-associated evolution of single-neuron activities.}
}



