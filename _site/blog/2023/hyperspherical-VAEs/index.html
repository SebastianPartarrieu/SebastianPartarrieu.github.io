<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>S. Partarrieu | Hyperspherical Variational Auto-Encoders</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2023/hyperspherical-VAEs/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-J228W495ML"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-J228W495ML');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       S. Partarrieu
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/Publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <!-- _layouts/post.html -->






<div class="post">

  <header class="post-header">
    <h1 class="post-title">Hyperspherical Variational Auto-Encoders</h1>
    <p class="post-meta">April 6, 2023</p>
    <p class="post-tags">
      <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>
      
        ·  
        
        <a href="/blog/tag/math">          <i class="fas fa-hashtag fa-sm"></i> math</a>  
          
        <a href="/blog/tag/code">          <i class="fas fa-hashtag fa-sm"></i> code</a>  
          
        <a href="/blog/tag/papers">          <i class="fas fa-hashtag fa-sm"></i> papers</a>  
          
      

      
    </p>
  </header>

  <article class="post-content">
    <div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/stable_diff_hvae.jpeg" alt="" title="H-VAE" width="400" height="200">
    </div>
<div class="caption">
    Hyperspherical variational autoencoders (generated using Stable Diffusion)
</div>

<p>“<strong>OMG</strong>, have you seen [insert latest OpenAI GPT model], isn’t it amazing !???”</p>

<p>For all those who are getting a little irritated at the sheer quantity of noise in the recent hype cycle, and of all the former web3.0/crypto-heads now going “all-in” on AI: you’ve come to the right place. Let’s forget about the hype and about <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/" target="_blank" rel="noopener noreferrer">how we’re all supposedly going to die</a>, heck let’s even forget about the transformer architecture and GPT-style generative models. Instead, why don’t we lay back, do some math, and have a look at another type of probabilistic generative model - the variational autoencoder (VAE). Don’t worry, this won’t be the million-th blog post explaining how these work, instead I’ll be diving into a recent(ish) flavor of VAE: the <a href="https://arxiv.org/pdf/1804.00891.pdf" target="_blank" rel="noopener noreferrer">Hyperspherical VAE</a>. These modify the posterior to use non-Gaussians distributions such as the von Mises-Fisher (vMF) distributions, which can be interesting when we expect the latent structure to exhibit some hyperspherical properties. Plus, not only does hyperspherical latent structure <em>sound</em> cool but it also gives some neat visualizations. So, if you have 5 mins of your precious time to spare, we can go through the paper together and I’ll show you a few fun experiments we were able to implement which allowed us to play with the original code and try to bump performance a little.</p>

<h2 id="a-primer-on-vaes">A primer on VAEs</h2>
<p>If you’re still reading at this point, I’m guessing you weren’t bored by the ML jargon above and hopefully this means you also already kind of know how a VAE works. For our purposes, a VAE looks something like this:</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/VAE_blog.png" alt="" title="VAE" width="500" height="300">
    </div>
<div class="caption">
    Simplified VAE
</div>

<p>You take input data \(X \in \mathbb{R}^{n \times d}\) (\(n\) samples and \(d\) dimensions) which you represent by a latent variable \(Z\). Now, in a traditional autoencoder, \(Z \in \mathbb{R}^{n \times d_{latent}}\) will usually be the output of a neural network that simply has an output dimension \(d_{latent}\) which is smaller than \(d\). You compress the data to a latent space with fewer dimensions, then de-compress it using a neural network decoder back into the original space. The <em>variational</em> framework changes this by considering <strong>probabilistic representations</strong> for \(X\) and \(Z\). This means each input will be encoded into a distribution rather than a single value. You may be wondering at this point, why is using probabilities interesting and why should we care about having a latent distributional encoding?</p>

<p>Well, if we consider \(X\) to follow a certain distribution, we can frame the problem as maximizing the log-likelihood of the data \(\log p_{\tau}(x)\) where \(\tau\) parametrizes our input data distribution. This is interesting as if we have the “optimal” parameter that adequately describes our input distribution, then we can sample from the input space directly which means generating new images (hence the name probabilistic generative model). Since the images will be drawn from the “same” distribution as our training set, hopefully this means these won’t look like random noise. The problem is that we don’t know how to optimize \(p_{\tau}(x)\) directly. Let’s imagine an input space of images of cats, you can’t really say “let’s find the best mean and stdev for a multi dimensional gaussian that fits these images” - no gaussian distribution would ever fit that remotely well. Instead, we can consider a latent variable \(Z\) that generates our observations. The nice thing is, we can imagine this latent variable to follow any distribution we would like. This means if we can reframe the optimization of our likelihood to include terms with respect to our latent variable, we have a fighting chance of being able to include reasonable prior assumptions and actually compute the thing.</p>

<p>More mathematically, consider \(\log p_{\tau}(x)\) within the variational framework: we marginalize over the latent space distribution \(p_{\tau}(x) = \int_{z}^{} p_{\tau}(x, z) \,dz\) and rewrite this is as \(p_{\tau}(x) = \int_{z}^{} p_{\tau}(x \| z)p_{\tau}(z) \,dz\). Without going into further detail (see <a href="https://en.wikipedia.org/wiki/Variational_autoencoder#:~:text=Variational%20autoencoders%20are%20probabilistic%20generative,first%20and%20second%20component%20respectively." target="_blank" rel="noopener noreferrer">Wiki</a>), you can optimize a lower bound of the log of this integral by maximizing the Evidence Lower Bound (ELBO) \(\mathbb{E}_{q_{\psi}(z \| x)}[ \log p_{\theta}(x \| z)] - KL(q_{\psi}(z \| x) \| p_{\tau}(z))\). Here, \(q_{\psi}(z \| x)\) represents our approximate posterior distribution (which is why we use q and not p). This approximate posterior is taken from a family of distributions (e.g. gaussian or vMF as we will see later) and we parametrize it by \(\psi\). In practice this parametrization refers to the encoder neural network that will output the parameters of the posterior distribution given an input. In the simplified VAE shown above, these parameters correspond to the mean and standard deviation of a gaussian distribution. <strong>The main idea of the paper is to consider a vMF distribution for the posterior which gives the latent space “hyperspherical” properties. They also provide the theoretical work needed to backpropagate to find the parameters of the vMF distribution where previous work had considered one of the parameters as constant.</strong></p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/main_contribution_hvae.jpg" alt="" title="main_contribution" width="500" height="300">
    </div>
<div class="caption">
    The paper's main contribution
</div>

<h2 id="the-vmf-distribution">The vMF distribution</h2>
<p>The von-Mises Ficher distribution is interesting to consider as a prior for a number of reasons. First, it is not a gaussian. This may sound kind of dumb but honestly, it is not a bad first-order approximation to say that sometimes the best you can do to try and improve a certain method is to find where the algorithm relies on the assumption that the underlying distribution is gaussian and <strong>ditch</strong> that. A little more seriously, the von-Mises Fisher is adapted for hyperspherical distributions. Specifically, it is a probability distribution defined on the surface of a hypersphere (a sphere in a potentially high-dimensional space). As you can see in the cute visualization below, it’s quite useful to model directional data on this hypersphere as the \(\kappa\) parameter controls the concentration of the distribution aruond a specific direction. The pdf looks like this \(f(x | \mu, \kappa) = C(\kappa)\exp(\kappa \mu^Tx)\) where \(x\) can be of any dimension. For our purposes we don’t really need to know what \(C(\kappa)\) is (it’s just a normalization constant) but what’s import to note is that as \(\kappa\) increases, the distribution gets more concentrated around the mean \(\mu\) direction.</p>

<p>Some <a href="https://github.com/EmmaBouhanna/HM-SVAE" target="_blank" rel="noopener noreferrer">messy code</a> shows this very well:</p>
<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/vMF_sampling_base.jpg" alt="" title="sampling_vMF" width="500" height="300">
    </div>
<div class="caption">
    Sampling the vMF distribution
</div>

<h2 id="kl-divergence-and-vmf-sampling">KL divergence and vMF sampling</h2>
<p>Since everything is probabilistic, to decode an input with the decoder we need to be able to sample from the latent space. Also, to backprogate the loss and update the distribution parameters (all the guides I was mentioning should have explained to you how the reparametrization trick helps with this) we need the reparametrization trick to make sure we can actually differentiate with respect to the distribution parameters. The paper deals with both of these issues nicely. The main component of the vMF sampling corresponds to <a href="https://en.wikipedia.org/wiki/Rejection_sampling" target="_blank" rel="noopener noreferrer">acceptance rejection sampling</a> with a clever reparametrization trick you can see highlighted below:</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/algo1_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300">
    </div>
<div class="caption">
    Sampling the vMF distribution, the main algorithm
</div>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/param_trick_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300">
    </div>
<div class="caption">
    Sampling the vMF distribution, acceptance rejection
</div>
<p>Although the specifics are somewhat painful, we sought to see if we could play around with the sampling implemented in the paper. Was there perhaps a better sampling method? Would it impact performance?</p>

<h2 id="modifying-the-sampling-mechanism-from-the-original-paper">Modifying the sampling mechanism from the original paper</h2>
<p>So, we looked into how we could modify the acceptance rejection sampling to something else. This was really more to get a sense of the code and to implement a sampler rather than because some theoretical insights might have suggested a better sampler could improve the H-VAEs performance. You can see below the exact sampling algorithm we decided to implement (the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" target="_blank" rel="noopener noreferrer">Metropolis-Hastings algorithm</a>) which basically amounts to just changing the ratio used to reject samples.</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/HM_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300">
    </div>
<div class="caption">
    Sampling the vMF distribution, Hasting Metropolis sampler
</div>

<p>It was fun to be able to code this and to see if there was any real impact on performance/how the samplers differed. We can actually compare the new sampling without all the VAE around it. Let’s take the sampling of the vMF we saw previously and compare it to the HM sampler. We can see that the HM is slightly more exploratory with a distribution that seems to be more spread out for a same value of \(\kappa\).</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/HM_vs_base_sampling_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300">
    </div>
<div class="caption">
    Sampling the vMF distribution, HM versus acceptance rejection
</div>

<h2 id="mnist-reconstruction">MNIST reconstruction</h2>
<p>(Yes, we’re <em>still</em> using MNIST for experiments, even in 2023…). The final thing we wanted to test was to see if this modified sampling actually had any impact on this H-VAEs performance. To test this, we take the one and only OG MNIST dataset. The experiment solely consists in running the training of the H-VAE on MNIST and then looking at the training and testing performance when we use either sampler. Long story short, there’s no real training or testing loss performance. This was kind of to be expected since we did not change the sampler substantially but, intuitively, if you’re able to sample better from the posterior distribution your performance shoult get better.</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/hvae_MNIST_training_loss.jpg" alt="" title="HVAE training loss" width="500" height="300">
    </div>
<div class="caption">
    MNIST reconstruction experiment, comparing samplers
</div>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/hvae_MNIST_testing_loss.jpg" alt="" title="HVAE testing loss" width="500" height="300">
    </div>
<div class="caption">
    MNIST reconstruction experiment, comparing samplers
</div>

<h2 id="visualizing-the-latent-space">Visualizing the latent space</h2>
<p>Finally, for some cool visuals, it’s always nice to look at the latent space. In this case, we can look at how the various MNIST digits are distributed across the hypersphere and how digits that resemble each other lie closer in the latent space.</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/hvae_latent_space_sampling.jpg" alt="" title="HVAE latent space sampling" width="500" height="300">
    </div>
<div class="caption">
    Visualizing the H-VAE latent space
</div>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/basic_animation.gif" alt="" title="HVAE latent space sampling" width="500" height="300">
    </div>
<div class="caption">
    Visualizing the H-VAE latent space, each color is a digit
</div>

<h2 id="conclusion">Conclusion</h2>

<p><em>Originally, this was a short project carried out by <a href="https://www.linkedin.com/in/emma-bou-hanna/" target="_blank" rel="noopener noreferrer">Emma Bou Hanna</a> &amp; me (Sebastian Partarrieu) for the <a href="https://www.master-mva.com/cours/computational-statistics/" target="_blank" rel="noopener noreferrer">Computational Statistics course</a> of the MVA master’s degree.</em></p>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    © Copyright 2023 Sebastian A. Partarrieu.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: December 27, 2023.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
