<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-01T23:20:00+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">S. Partarrieu</title><subtitle></subtitle><entry><title type="html">A year for action and intentionality</title><link href="http://localhost:4000/blog/2025/the-year-ahead/" rel="alternate" type="text/html" title="A year for action and intentionality" /><published>2025-01-05T16:12:00+01:00</published><updated>2025-01-05T16:12:00+01:00</updated><id>http://localhost:4000/blog/2025/the-year-ahead</id><content type="html" xml:base="http://localhost:4000/blog/2025/the-year-ahead/"><![CDATA[<p>As a child, my favorite bedtime story was <em>David and Goliath</em>. I would ask for it every night, and I must have heard it hundreds of times. Yet, it continuously struck a chord with small Sebastian who, as the youngest of 4, felt like the underdog in many situations. David’s courage gave me hope, and a deep belief that despite being the youngest and smallest (at the time) of the family, I could still do great things.</p>

<p>Looking back, I realize a lot of my life has been shaped by this desire to prove myself by taking on my own Goliaths. The Philistine champion may have evolved over the years, but there’s always been one.</p>

<p>This year, Goliath is twofold: the market and time. As I kick off 2025 by working on my own project (more on that soon), I hope to use my sling and stone effectively, and fight to bring the project to <em>default-alive</em>. It’ll require action, and lots of it. So here’s to a year of action and intentionality! May we all apply it to the important facets of life - health, fitness, relationships, learning and building.</p>]]></content><author><name></name></author><category term="entrepreneurship" /><summary type="html"><![CDATA[Wishing you all a great 2025]]></summary></entry><entry><title type="html">Building an AI Startup</title><link href="http://localhost:4000/blog/2024/learnings-AI-startup-school/" rel="alternate" type="text/html" title="Building an AI Startup" /><published>2024-04-07T17:12:00+02:00</published><updated>2024-04-07T17:12:00+02:00</updated><id>http://localhost:4000/blog/2024/learnings-AI-startup-school</id><content type="html" xml:base="http://localhost:4000/blog/2024/learnings-AI-startup-school/"><![CDATA[<p>I recently attended Entrepreneur First’s <a href="https://www.joinef.com/ai-startup-school/">AI Startup School</a>, a series of evening lectures with some of the most interesting figures in the (Parisian) AI/ML startup space. Speakers included builders (Eiso Kant from <a href="https://www.poolside.ai/">Poolside</a>, Gabriel Hubert from <a href="https://dust.tt/">Dust</a>, Arthur Mensch from <a href="https://mistral.ai/">Mistral</a>, Emad Mostaque from <a href="https://stability.ai/">Stability</a>, Karim Beguir from <a href="https://www.instadeep.com/">InstaDeep</a>, …) and investors (Alexis Robert from <a href="https://www.kimaventures.com/">Kima</a>, Antoine Moyroud from <a href="https://lsvp.com/">LightSpeed</a>, Matt Clifford from <a href="https://www.joinef.com/">Entrepreneur First</a>) which gave a mix of perspectives and many topics to cover. This blog post is my attempt to distill down some of the main learnings <strong><u>I</u></strong> took from this great lecture series, whose structure and contents went far beyond what I write here. For context, it was aimed towards recent technical graduates who are interested in entrepreneurship - some of the advice and analysis of the space was made with the audience in mind.</p>

<ul>
  <li><a href="#what-to-think-about">What to think about</a>
    <ul>
      <li><a href="#up-or-across">Up or across?</a></li>
      <li><a href="#data">Data</a></li>
      <li><a href="#llm-onomics">LLM-onomics</a></li>
    </ul>
  </li>
  <li><a href="#dealing-with-venture-capitalists">Dealing with venture capitalists</a>
    <ul>
      <li><a href="#vc-the-asset-class">VC, the asset class</a></li>
      <li><a href="#vc-investment-is-a-market">VC investment is a market</a></li>
      <li><a href="#judging-startups">Judging startups</a></li>
    </ul>
  </li>
  <li><a href="#advice--conclusion">Advice &amp; conclusion</a></li>
</ul>

<h2 id="what-to-think-about">What to think about</h2>
<p>As the name of the lecture series suggests, we often discussed <strong>what to think about when building an AI startup</strong>. To us, an “AI” startup is one that builds in a few of the broad layers making up the AI stack: hardware, foundational models, infrastructure/tooling, and applications. Of these parts of the stack, the foundational and application layers were by far the most represented during the lecture series, and will also be overrepresented in this post.</p>

<p>So, what are the main questions you should ask yourself if you’re trying to build one? For both the model and application layers, any AI startup takes a stance on whether they want to build vertically or horizontally. Then, regardless of that choice, all speakers agreed that focusing extensively on your data is probably a good idea. Finally, let’s say you have a good model trained on great data, you want to think about how you monetize it.</p>

<h3 id="up-or-across">Up or across?</h3>
<p>If you’re building a foundational model, going by the definition of “foundational”, it might seem you’re building something horizontal in nature. While this is true, many speakers working on foundational models didn’t seem to agree that we are converging towards “one model to rule them all”. Instead of having a single model that outperforms humans on all intelligence-related tasks, we will likely have lots of more specialized models that are vertically integrated, each beating more general models in their specific area of training. As a foundational model provider, you take a stance on whether you believe models should be vertically integrated versus focusing on generalist models.</p>

<p>For companies like Poolside, this translates to focusing heavily on code as an input data modality for their LLMs. This allows them to build specialized training paradigms such as “Reinforcement Learning via code execution feedback”, where they leverage unit tests, compiler checks, and other code-specific validity signals as inputs to a reward model. For Stability, this means focusing heavily on image, speech, and non-text data modalities, while taking it a step further and fine-tuning models for specific use cases such as a partnership with Bollywood. To them, if humans spend years specializing and curating their input data, it seems reasonable to assume models will also function as specialists with narrow domain expertise. For Mistral, this means developing (mostly) open-source LLMs without imposing an editorial tone, allowing developers and customers to fine-tune models on their vertical-specific data. Of course, companies like Mistral and Stability are better described as building horizontally as they focus on one of the core technologies of this AI wave, but I would argue they err on the side of specialization and vertical integration as they sell modularity as a feature. OpenAI, on the other hand, seems to be pushing for a world where a single model will do all of these things, which strikes me as less likely.</p>

<p>Whether you can build a successful AI startup focusing on the core technology itself versus the application layer is mostly a function of your credibility, capabilities, and capital - with the former requiring a higher dose of each. This means that, as a young entrepreneur, you might be better off building with a specific industry in mind. Though it may be criticized as building a “ChatGPT wrapper”, focusing deeply on a specific use case means you get to know your training data, and perhaps, more importantly, you can understand the real problems your industry of choice faces - which is where you should start. In this vain, many traditional industries face challenges where AI can offer new insights, but incumbents don’t adopt new technologies quickly. If you know an industry’s problems deeply and can understand where AI offers value in the solutions and why existing companies aren’t adopting it, you’re off to a decent start.</p>

<p>A great example during the lecture series was <a href="https://www.spore.bio/">Spore.bio</a>, which got started with the observation that microbial monitoring in food factories is often performed using old technologies (think of the Petri dish you used in high school). It turns out newer imaging techniques combined with computer vision algorithms can help you monitor microbe presence more efficiently. Although it’s still early days, this company, much to their credit, identified a traditional industry’s inefficiency, got to know the specific data deeply, and applied AI thoughtfully. A final interesting note is that verticalized solutions are often less prone to competition from big tech giants. Matt explained this with a simple thought experiment: “Say you’re Satya, Tim, Sundar, etc. You wake up in the morning and what do you think about? Mostly about opportunities that can bring $10B + incremental revenue per quarter. You’re not thinking about legal tech.” Given the number of failed launches and retracted products by Google, there must be some truth to this.</p>

<h3 id="data">Data</h3>
<p>To learn, any machine learning model needs access to good data. As we’ve mentioned, a focused AI application developer can reap the benefits of accessing and obsessing over data specific to their use case of interest. But even for companies like Mistral, data represents a significant part of their efforts and competitive advantage. So, a universal rule of any model to application layer AI startup is: get good data and lots of it. This can seem difficult at first, especially when you’re operating in an industry where data is siloed or held by incumbents. Paradoxically, as an early-stage startup, asking these companies for samples of their data with a clear explanation of the problem you want to solve offers useful signal for your project. If you’re trying to solve an important pain point of theirs, they will likely share their data with you. Even if they don’t, you can tell whether they won’t share data because they’re not interested in what you’re doing or because they consider that data to be a core asset of theirs. Either way, you’ll know if they find your work interesting.</p>

<p>You can also try to generate some of your data. For “verifiable” data modalities such as code, since you can (more or less) check the output of your model you could argue that using synthetic data becomes more viable - as you’ll be able to filter out poor generations. However, Arthur Mensch argues that regardless of the filtering, training on generated outputs does not increase the complexity of the generative process from an information theoretic perspective. This means you can’t hope to train on your outputs and continue increasing model capabilities across the board. What was left unmentioned is that filtering outputs and using these as training data to increase performance on certain narrow tasks is effectively tightening the output distribution of your model, which could be interesting for application developers. Although it’s an unsatisfying answer, using synthetic data is dependent on how you generate/filter them and what the end goal is.</p>

<p>Finally, even when you have access to lots of high-quality data, you can play on the data mix when training your models to, literally, optimize for specific model behavior. Upsampling code is a bet Poolside has taken, with 50% of their LLM training input data (at the pretraining phase) being code. Most foundational model builders seem to upsample reputable data sources in their input training data during pre-training or fine-tuning stages. This generalizes to all AI startups <em>training</em> model: you need to be thoughtful of the input data mix, which is often an experimental science.</p>

<h3 id="llm-onomics">LLM-onomics</h3>
<p>Now that you have some workable model, how do you make money? For foundational model providers, both API usage fees and subscription-based models can be viable. When it comes to your average end user, it seems the subscription-based model OpenAI launched with GPT-4 accessible for $20/month has become the <em>de-facto</em> industry standard (we could still see ad-based business models take off, but we’ll just have to wait and see how that plays out).</p>

<p>On the developer side, Emad Mostaque didn’t seem to believe in a durable API $/token business model. First off, developers calling models locked behind APIs have close to no switching costs when deciding to switch out one model provider against another. This results in the strongest model to date being used at the prototyping phase and then more lightweight, cost-efficient, models being used in production. Following the absence of switching costs, competition between model providers to offer the lowest $/token brings margins down. On the other hand, a subscription-based model where you can download the latest models against a recurring fee solves some of these problems. Developers like having access to the models to be able to fine-tune and customize them, and being able to serve them locally is a must for heavily regulated industries where you can’t send private data to a closed API, no matter how clean the terms and conditions are. Integrating models in your code base, and serving them on your infrastructure, close to your data, also means you’re less likely to switch to tomorrow’s next state-of-the-art model. So, giving developers more control also leads to higher switching costs, which seems like a win-win for everyone involved.</p>

<p>More specialized AI application developers will likely default to tried and tested business models based on their end users. Dust offers a per-user monthly pricing plan like most SaaS companies do. My (uneducated) guess is other companies in the space are following suit - innovating on the product is hard enough.</p>

<h2 id="dealing-with-venture-capitalists">Dealing with venture capitalists</h2>
<p>If you’re building an AI startup, you may need money to get you started. If you do, <em>one</em> possible way of getting some is speaking to venture capitalists. Of the chats I found most interesting during this series, in the sense that it was on a topic I knew the least about, was one with VCs Antoine and Alexis from LightSpeed and Kima. Understanding VCs well should be a prerequisite to accepting any money from them, so let’s try to grasp their side of the equation.</p>

<h3 id="vc-the-asset-class">VC, the asset class</h3>
<p>At a high level, venture capital is an asset class. Taking <a href="https://www.investopedia.com/terms/a/assetclasses.asp#:~:text=popular%20asset%20classes%3F-,Historically%2C%20the%20three%20main%20asset%20classes%20have%20been%20equities%20(stocks,in%20the%20asset%20class%20mix.)">investopedia’s definition</a>, “an asset class is a grouping of investments that exhibit similar characteristics and that may be subject to the same rules and regulations”. This essentially means VC is a specific type of investment. As an investment, venture capital is expected to make more money than what was initially invested. Its specificity, or grouping characteristic, is that it mainly targets high-growth projects such as <em>startups</em>. Generally, these are considered high-risk high-reward investments, so any good VC firm is expected to return a multiple of what was initially put in.</p>

<p>But, where does it get the money it invests? Usually, it takes money from larger investors, then invests it in startups (while taking in a certain % in management fees), before giving the investors their money back + profits. This characterization highlights the split in a venture capitalist’s job: they (i) find and secure money and (ii) find, research, and secure deals. Additionally, they make sure the deals they took part in work out i.e. they try to help founders they backed. What’s important to understand in all this is that the venture capitalists’ <strong>main job</strong> is to make more money than what was given to her. This might all seem very obvious, but it’s crucial to understand the main incentives driving the person you’re talking to. When a VC is sourcing, researching, or securing deals (or helping after a deal), their main focus is making more money than what they invested. Of course, there are slight deviations from this job description in VC land. Kima Ventures is a good example, as they have only one investor: Xavier Niel. This means that they focus heavily on (ii) since (i) is secured - but this doesn’t change their underlying mission.</p>

<h3 id="vc-investment-is-a-market">VC investment is a market</h3>
<p>The second part of a VC job is what’s most important to founders, namely investing in startups. Put simply, investing in a startup means <em>buying</em> shares of that startup against money. So, VCs are <em>buyers</em> and startups are <em>sellers</em> - and when there are buyers and sellers we usually refer to it as a <em>market</em>. Although startup shares are a very specific type of good, the usual laws of supply and demand apply. A good example is the so-called “ZIRP” (zero-interest-rate policy) era from 2020 to 2022 which led to plentiful demand (lots of buyers); this meant startups were able to gain huge valuations (great prices) with shaky business models and bad fundamentals. Market dynamics explain many of these phenomena, as too many buyers mean they’re more worried about losing deals than the product they’re buying. Put more fancifully, the amount of due diligence depends on current market conditions.</p>

<p>As a seller (founder), your product (startup shares) is going to be judged against other similar products available in the market around a similar period. Execution speed, initial business metrics, etc. will all be judged relatively to other actors in the market, which means it’s your job to make sure you’re doing better than the average i.e. that you have a good product. But even with a good product, it’s also your job to sell it well - at the best possible price. As with traditional goods such as sneakers, you can create a sense of urgency and exclusiveness to what you’re selling. And it turns out VCs respond to FOMO very well: use this and create that waiting line in front of the hypothetical startup share store…</p>

<h3 id="judging-startups">Judging startups</h3>
<p>Yes, you’ll be judged relatively, but what exactly makes a great product for a VC to buy in the first place? It seems Kima has a standard set of questions addressed to founders and designed to assess this. These boil down to: how did you meet? how &amp; when did you have the idea? when did you start full-time? what is the current status? what are the next steps?</p>

<p>The goal behind these questions is to judge the speed of execution, and the plans/ambition for the startup. Speed of execution and learning are indeed core criteria on which you are judged as a founder. Execution speed is so important that Alexis further broke down how execution speed can be measured. There is the speed of how you pitch, as your idea should be clear in 1-2 sentences. There is the growth of your north star metric, and note that growth is much more important than any absolute value at these early stages. There is also execution speed on operational metrics such as hiring. If you can show some of the dots going up and to the right, the extrapolation will be done for you.</p>

<h2 id="advice--conclusion">Advice &amp; conclusion</h2>
<p>By now, we have a rough idea of <em>some</em> of the questions (and an even rougher understanding of possible answers) we should be asking ourselves if we’re building an AI startup and if we want to raise venture capital money. Of course, plenty has been left unasked and unanswered - it will have to be lived.</p>

<p>In the guise of a conclusion, I’ll leave here bits and pieces of advice that were offered to us over these few weeks. As Karim Beguir mentioned, great advice requires enough context; much of this advice is, however, worth engaging with:</p>

<ul>
  <li>If you want to build a product, read <a href="https://www.momtestbook.com/">the Mom test</a></li>
  <li>To get better at hiring, read <a href="https://www.amazon.com/Who-Method-Hiring-Geoff-Smart-ebook/dp/B001EL6RWY">Who: The A Method for Hiring</a></li>
  <li>Read as much as possible about the entrepreneurs you admire. Track what they said and what they achieved</li>
  <li>Worth repeating: do something you’re passionate about, that you’re world-class at, and that solves a real problem</li>
  <li>If you have the above, you don’t need to worry too much about funding, it will come</li>
  <li>You need to be ready to “go through the motions”, and doing something you’re passionate about is a great way to not quit</li>
  <li>Deep tech usually requires deep expertise or deep pockets</li>
  <li>If you have a genuine urge to found a company, you might not need that PhD - the learning curve is steeper with the former</li>
  <li>Everything is a power law in a startup: outcomes, hiring, etc.</li>
  <li>You need to use whatever unfair advantages you have</li>
  <li>Speak to your customer</li>
  <li>Don’t be afraid to be ambitious, and don’t be afraid to communicate that ambition clearly and unapologetically</li>
</ul>

<p>There you have it! Thanks EF for organizing this lecture series, it’s inspiring to see the Parisian startup ecosystem flourish - we all learned a lot.</p>]]></content><author><name></name></author><category term="AI" /><category term="entrepreneurship" /><summary type="html"><![CDATA[Building an AI startup, key takeaways from EFs AI Startup School]]></summary></entry><entry><title type="html">Web pages and LLMs, A Match Made in Heaven</title><link href="http://localhost:4000/blog/2023/web-pages-and-llms/" rel="alternate" type="text/html" title="Web pages and LLMs, A Match Made in Heaven" /><published>2023-11-24T16:12:00+01:00</published><updated>2023-11-24T16:12:00+01:00</updated><id>http://localhost:4000/blog/2023/web-pages-and-llms</id><content type="html" xml:base="http://localhost:4000/blog/2023/web-pages-and-llms/"><![CDATA[<p>TL;DR I worked on using large language models (LLMs) to automate web page understanding as a Machine Learning research intern @ Joko. In the space of six months I was able to get some great results on open benchmarks and work towards scaling the solution to processing hundreds of millions of web pages. It was super fun!</p>

<p>For the entire blog post, check it out <a href="https://engineering.joko.com/posts/webpages-and-llms-a-match-made-in-heaven/">here</a>!</p>]]></content><author><name></name></author><category term="math" /><category term="code" /><category term="papers" /><summary type="html"><![CDATA[How LLMs can help us understand & interact with web pages automatically]]></summary></entry><entry><title type="html">Hyperspherical Variational Auto-Encoders</title><link href="http://localhost:4000/blog/2023/hyperspherical-VAEs/" rel="alternate" type="text/html" title="Hyperspherical Variational Auto-Encoders" /><published>2023-04-06T17:12:00+02:00</published><updated>2023-04-06T17:12:00+02:00</updated><id>http://localhost:4000/blog/2023/hyperspherical-VAEs</id><content type="html" xml:base="http://localhost:4000/blog/2023/hyperspherical-VAEs/"><![CDATA[<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/stable_diff_hvae.jpeg" alt="" title="H-VAE" width="400" height="200" />
    </div>
<div class="caption">
    Hyperspherical variational autoencoders (generated using Stable Diffusion)
</div>

<p>“<strong>OMG</strong>, have you seen [insert latest OpenAI GPT model], isn’t it amazing !???”</p>

<p>For all those who are getting a little irritated at the sheer quantity of noise in the recent hype cycle, and of all the former web3.0/crypto-heads now going “all-in” on AI: you’ve come to the right place. Let’s forget about the hype and about <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">how we’re all supposedly going to die</a>, heck let’s even forget about the transformer architecture and GPT-style generative models. Instead, why don’t we lay back, do some math, and have a look at another type of probabilistic generative model - the variational autoencoder (VAE). Don’t worry, this won’t be the million-th blog post explaining how these work, instead I’ll be diving into a recent(ish) flavor of VAE: the <a href="https://arxiv.org/pdf/1804.00891.pdf">Hyperspherical VAE</a>. These modify the posterior to use non-Gaussians distributions such as the von Mises-Fisher (vMF) distributions, which can be interesting when we expect the latent structure to exhibit some hyperspherical properties. Plus, not only does hyperspherical latent structure <em>sound</em> cool but it also gives some neat visualizations. So, if you have 5 mins of your precious time to spare, we can go through the paper together and I’ll show you a few fun experiments we were able to implement which allowed us to play with the original code and try to bump performance a little.</p>

<h2 id="a-primer-on-vaes">A primer on VAEs</h2>

<p>If you’re still reading at this point, I’m guessing you weren’t bored by the ML jargon above and hopefully this means you also already kind of know how a VAE works. For our purposes, a VAE looks something like this:</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/VAE_blog.png" alt="" title="VAE" width="500" height="300" />
    </div>
<div class="caption">
    Simplified VAE
</div>

<p>You take input data \(X \in \mathbb{R}^{n \times d}\) (\(n\) samples and \(d\) dimensions) which you represent by a latent variable \(Z\). Now, in a traditional autoencoder, \(Z \in \mathbb{R}^{n \times d_{latent}}\) will usually be the output of a neural network that simply has an output dimension \(d_{latent}\) which is smaller than \(d\). You compress the data to a latent space with fewer dimensions, then de-compress it using a neural network decoder back into the original space. The <em>variational</em> framework changes this by considering <strong>probabilistic representations</strong> for \(X\) and \(Z\). This means each input will be encoded into a distribution rather than a single value. You may be wondering at this point, why is using probabilities interesting and why should we care about having a latent distributional encoding?</p>

<p>Well, if we consider \(X\) to follow a certain distribution, we can frame the problem as maximizing the log-likelihood of the data \(\log p_{\tau}(x)\) where \(\tau\) parametrizes our input data distribution. This is interesting as if we have the “optimal” parameter that adequately describes our input distribution, then we can sample from the input space directly which means generating new images (hence the name probabilistic generative model). Since the images will be drawn from the “same” distribution as our training set, hopefully this means these won’t look like random noise. The problem is that we don’t know how to optimize \(p_{\tau}(x)\) directly. Let’s imagine an input space of images of cats, you can’t really say “let’s find the best mean and stdev for a multi dimensional gaussian that fits these images” - no gaussian distribution would ever fit that remotely well. Instead, we can consider a latent variable \(Z\) that generates our observations. The nice thing is, we can imagine this latent variable to follow any distribution we would like. This means if we can reframe the optimization of our likelihood to include terms with respect to our latent variable, we have a fighting chance of being able to include reasonable prior assumptions and actually compute the thing.</p>

<p>More mathematically, consider \(\log p_{\tau}(x)\) within the variational framework: we marginalize over the latent space distribution \(p_{\tau}(x) = \int_{z}^{} p_{\tau}(x, z) \,dz\) and rewrite this is as \(p_{\tau}(x) = \int_{z}^{} p_{\tau}(x \| z)p_{\tau}(z) \,dz\). Without going into further detail (see <a href="https://en.wikipedia.org/wiki/Variational_autoencoder#:~:text=Variational%20autoencoders%20are%20probabilistic%20generative,first%20and%20second%20component%20respectively.">Wiki</a>), you can optimize a lower bound of the log of this integral by maximizing the Evidence Lower Bound (ELBO) \(\mathbb{E}_{q_{\psi}(z \| x)}[ \log p_{\theta}(x \| z)] - KL(q_{\psi}(z \| x) \| p_{\tau}(z))\). Here, \(q_{\psi}(z \| x)\) represents our approximate posterior distribution (which is why we use q and not p). This approximate posterior is taken from a family of distributions (e.g. gaussian or vMF as we will see later) and we parametrize it by \(\psi\). In practice this parametrization refers to the encoder neural network that will output the parameters of the posterior distribution given an input. In the simplified VAE shown above, these parameters correspond to the mean and standard deviation of a gaussian distribution. <strong>The main idea of the paper is to consider a vMF distribution for the posterior which gives the latent space “hyperspherical” properties. They also provide the theoretical work needed to backpropagate to find the parameters of the vMF distribution where previous work had considered one of the parameters as constant.</strong></p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/main_contribution_hvae.jpg" alt="" title="main_contribution" width="500" height="300" />
    </div>
<div class="caption">
    The paper's main contribution
</div>

<h2 id="the-vmf-distribution">The vMF distribution</h2>

<p>The von-Mises Fisher distribution is interesting to consider as a prior for a number of reasons. First, it is not a gaussian. This may sound kind of dumb but honestly, it is not a bad first-order approximation to say that sometimes the best you can do to try and improve a certain method is to find where the algorithm relies on the assumption that the underlying distribution is gaussian and <strong>ditch</strong> that. A little more seriously, the von-Mises Fisher is adapted for hyperspherical distributions. Specifically, it is a probability distribution defined on the surface of a hypersphere (a sphere in a potentially high-dimensional space). As you can see in the cute visualization below, it’s quite useful to model directional data on this hypersphere as the \(\kappa\) parameter controls the concentration of the distribution around a specific direction. The pdf looks like this \(f(x \| \mu, \kappa) = C(\kappa)\exp(\kappa \mu^T x)\) where \(x\) can be of any dimension. For our purposes we don’t really need to know what \(C(\kappa)\) is (it’s just a normalization constant) but what’s import to note is that as \(\kappa\) increases, the distribution gets more concentrated around the mean \(\mu\) direction.</p>

<p>Some <a href="https://github.com/EmmaBouhanna/HM-SVAE">messy code</a> shows this very well:</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/vMF_sampling_base.jpg" alt="" title="sampling_vMF" width="500" height="300" />
    </div>
<div class="caption">
    Sampling the vMF distribution
</div>

<h2 id="kl-divergence-and-vmf-sampling">KL divergence and vMF sampling</h2>

<p>Since everything is probabilistic, to decode an input with the decoder we need to be able to sample from the latent space. Also, to backprogate the loss and update the distribution parameters (all the guides I was mentioning should have explained to you how the reparametrization trick helps with this) we need the reparametrization trick to make sure we can actually differentiate with respect to the distribution parameters. The paper deals with both of these issues nicely. The main component of the vMF sampling corresponds to <a href="https://en.wikipedia.org/wiki/Rejection_sampling">acceptance rejection sampling</a> with a clever reparametrization trick you can see highlighted below:</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/algo1_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300" />
    </div>
<div class="caption">
    Sampling the vMF distribution, the main algorithm
</div>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/param_trick_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300" />
    </div>
<div class="caption">
    Sampling the vMF distribution, acceptance rejection
</div>
<p>Although the specifics are somewhat painful, we sought to see if we could play around with the sampling implemented in the paper. Was there perhaps a better sampling method? Would it impact performance?</p>

<h2 id="modifying-the-sampling-mechanism-from-the-original-paper">Modifying the sampling mechanism from the original paper</h2>

<p>So, we looked into how we could modify the acceptance rejection sampling to something else. This was really more to get a sense of the code and to implement a sampler rather than because some theoretical insights might have suggested a better sampler could improve the H-VAEs performance. You can see below the exact sampling algorithm we decided to implement (the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolis-Hastings algorithm</a>) which basically amounts to just changing the ratio used to reject samples.</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/HM_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300" />
    </div>
<div class="caption">
    Sampling the vMF distribution, Hasting Metropolis sampler
</div>

<p>It was fun to be able to code this and to see if there was any real impact on performance/how the samplers differed. We can actually compare the new sampling without all the VAE around it. Let’s take the sampling of the vMF we saw previously and compare it to the HM sampler. We can see that the HM is slightly more exploratory with a distribution that seems to be more spread out for a same value of \(\kappa\).</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/HM_vs_base_sampling_hvae.jpg" alt="" title="sampling_vMF" width="500" height="300" />
    </div>
<div class="caption">
    Sampling the vMF distribution, HM versus acceptance rejection
</div>

<h2 id="mnist-reconstruction">MNIST reconstruction</h2>

<p>(Yes, we’re <em>still</em> using MNIST for experiments, even in 2023…). The final thing we wanted to test was to see if this modified sampling actually had any impact on this H-VAEs performance. To test this, we take the one and only OG MNIST dataset. The experiment solely consists in running the training of the H-VAE on MNIST and then looking at the training and testing performance when we use either sampler. Long story short, there’s no real training or testing loss performance. This was kind of to be expected since we did not change the sampler substantially but, intuitively, if you’re able to sample better from the posterior distribution your performance shoult get better.</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/hvae_MNIST_training_loss.jpg" alt="" title="HVAE training loss" width="500" height="300" />
    </div>
<div class="caption">
    MNIST reconstruction experiment, comparing samplers
</div>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/hvae_MNIST_testing_loss.jpg" alt="" title="HVAE testing loss" width="500" height="300" />
    </div>
<div class="caption">
    MNIST reconstruction experiment, comparing samplers
</div>

<h2 id="visualizing-the-latent-space">Visualizing the latent space</h2>

<p>Finally, for some cool visuals, it’s always nice to look at the latent space. In this case, we can look at how the various MNIST digits are distributed across the hypersphere and how digits that resemble each other lie closer in the latent space.</p>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/hvae_latent_space_sampling.jpg" alt="" title="HVAE latent space sampling" width="500" height="300" />
    </div>
<div class="caption">
    Visualizing the H-VAE latent space
</div>

<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" zoomable="true" src="/assets/img/basic_animation.gif" alt="" title="HVAE latent space sampling" width="500" height="300" />
    </div>
<div class="caption">
    Visualizing the H-VAE latent space, each color is a digit
</div>]]></content><author><name></name></author><category term="math" /><category term="code" /><category term="papers" /><summary type="html"><![CDATA[Dive into VAEs with non Gaussian distributions]]></summary></entry><entry><title type="html">Published! New brain-machine interface design</title><link href="http://localhost:4000/blog/2023/mesh-electronics-BMI/" rel="alternate" type="text/html" title="Published! New brain-machine interface design" /><published>2023-02-20T16:12:00+01:00</published><updated>2023-02-20T16:12:00+01:00</updated><id>http://localhost:4000/blog/2023/mesh-electronics-BMI</id><content type="html" xml:base="http://localhost:4000/blog/2023/mesh-electronics-BMI/"><![CDATA[<p>After months of hard work, <a href="https://www.nature.com/articles/s41593-023-01267-x">the manuscript</a> <em>Tracking neural activity from the same cells during the entire adult life of mice</em> is now finally available in Nature Neuroscience! This work was conducted by the <a href="https://liulab.seas.harvard.edu/">Jia Liu Group</a> and I was lucky to be a part of the effort during a six-month stint there. <strong>Disclaimer</strong>: as I worked mostly on the data analysis / machine-learning side of things (and only did so for a fairly small amount of time), I probably won’t cover the paper comprehensively - feel free to go check it out if you want to see the real deal. In addition, the goal here is to provide a somewhat concise overview of the paper, so don’t expect the nitty gritty details. Finally, you can also have a look at this <a href="https://twitter.com/ganoopyliujia/status/1627712813610471425">Twitter thread</a> from Pr. Liu himself going through some of the main contributions of the paper.</p>

<h2 id="pitch-your-paper">Pitch your paper</h2>
<p><a href="https://sebastianpartarrieu.github.io/blog/2021/BMI-techonology-review/">Brain-machine interface (BMI) hardware</a> comes in many shapes and sizes. As you may have noticed, this technology isn’t widespread yet which suggests a number of challenges remain to be solved. One important problem is probe drift: if you stick a small metal rod into someone’s brain it turns out that the rod doesn’t stay where you wanted. Instead, it slowly drifts over time causing damage along the way. This is a nuisance as the rod is what captures the electrical activity of your neurons, if it moves, you aren’t recording the same neurons anymore. And if you don’t record the same neurons stably over time, you can’t train effective algorithms to decode the underlying neural activity. You can <a href="https://www.nature.com/articles/s41551-020-0542-9">try and fix</a> this instability algorithmically, but there is only so much you can accomplish if the underlying signal isn’t stable. Another source of instability is that sticking a metal rod inside your brain provokes an immune response which means that immune cells will come and agglomerate around the probe. This also diminishes your ability to faithfully capture the underlying activity. <strong>This is where this paper and technology comes in</strong>, what if there’s an alternative design to the metal rod? It turns out that advances in electronics mean that flexible mesh <a href="https://www.nature.com/articles/s41928-022-00913-9">intefaces</a> are a viable solution. Essentially, flexible grid-like brain-machine interfaces can be precisely implanted and they do not suffer from the two shortcomings mentioned above. Their position doesn’t drift over time as neurons can weave themselves through the grid leading to a truly integrated interface and the immune response is relatively minor. The main contribution of the paper is demonstrating this within multiple mice and over a very long time period.</p>

<h2 id="deepish-dive">Deep(ish) dive</h2>
<p>Two main mesh interface designs were tested: the first is a 32 or 16-channel sparse electrode layout (Fig. 1a of the paper) and the second is a tetrode-like electrode array which conserves the mesh structure (Fig. 4a). One of the main benefits of the tetrode-like array is that the densely packed electrodes on one tetrode will record the same neurons simultaneously and this improves the accuracy of the <a href="http://www.scholarpedia.org/article/Spike_sorting#:~:text=Spike%20sorting%20is%20the%20grouping,activity%20of%20different%20putative%20neurons.">spike sorting</a>. Indeed, if you have four channels recording one neuron, that electrical activity is seen from four different sites and each site will record a slighly different amplitude and shape due to its relative position with respect to the firing neuron. Having this multitude of information dramatically improves the identification of individual neurons. So, we tested both designs across multiple experiments which provided an abundance of data. The two main experimental conditions consisted of (i) recording spontaneous activity (the mice move around freely) and (ii) behavior-dependent activity within the visual cortex (the mice stay fixed and are shown static and dynamic grating stimuli - lines on a screen). The second set of experimental conditions are essentially a safeguard to make sure the interface is <em>really</em> stable over time and we weren’t just lucky. This is because neurons in the primary visual cortex show fairly different responses to different gratings. This means showing a specific orientation of the lines on the screen will elicit a response from only a few neurons. If you vary the orientation and record the corresponding neurons while repeating this over multiple months you can be pretty sure that consistent activity with similar waveforms means BMI stability, which is the whole point!</p>

<p>Anyway, the main idea was to try and actually implant these things and see what happens. The first findings were that (Fig. 2) the mesh electronics actually integrate with the neuronal networks in the brain. Some pretty neat fluorescence imaging shows exactly what that looks like as well as how there are relatively few immune cells that come and disturb the electrode’s surroundings. This is encouraging as it suggests that these interfaces have a fighting chance of remaining stable over long time periods. So, quite naturally we looked at how we could quantify the stability of the recordings. We did so in both experimental conditions and the results were very promising.</p>

<h4 id="data-processing-pipeline">Data processing pipeline</h4>
<p>The data processing, signal stability and ML for unbiased signal analysis were my main areas of focus when participating in the project. I created the base code and repository that was used for most of the data analysis. The pipeline to process the recordings looks roughly like this. You start from a bunch of voltage time series sampled at 10kHz recorded for 10-30 min a few times a month for several months. You then do some filtering and processing before extracting the actual spiking events, i.e when a neuron is firing, by taking all the points above a certain voltage value and selecting the values around the threshold crossing. This gives you a big matrix bordering on a few million rows of potential spiking events for each electrode with the associated timestamp of each event. At this point, you would really like to sort the events by neuron. There are plenty of great ways of doing spike sorting but we chose to use <a href="https://mountainsort.readthedocs.io/en/latest/">MountainSort</a>. Once you’ve assigned putative units to spiking events you can start doing stability quantification. We focused on multiplying different approaches of testing the stability of the recording as this is one of the main claims of the paper. I coded most of the data processing in python and used <a href="https://spikeinterface.readthedocs.io/en/latest/overview.html">python wrappers</a> to some MATLAB and C++ code.</p>

<h4 id="quantifying-signal-stability-in-lifetime-recordings">Quantifying signal stability in lifetime recordings</h4>
<p>What is the easiest way to test signal stability? Well, since you have waveforms over time that have been attributed to one neuron, you can simply see if there is change. As we saw earlier, the relative position of the neuron with respect to the electrode is proportional to the amplitude of the recorded signal. If the electrode drifts over time, this is visible when looking at the amplitude of the recorded neurons which will decrease as the electrode moves further away (or increase if it moves closer). So, we can extract the amplitude of each waveform and compare the results month by month. Interestingly, with the tetrode-like array, since you have multiple electrodes recording the same neuron the amplitude shift is enough to describe the electrode displacement fairly precisely. Of course, there are lots of other features we can extract from the waveform other than the amplitude, so we compare all of these to have a comprehensive approach. We essentially found that there was very little variation over time, whichever feature you decided to look at.</p>

<p>Now, the problem is that maybe the features we chose in the first place aren’t the right ones. Maybe they don’t describe the waveform completely. Or perhaps, the electrode is drifting slightly but the nearby neurons have similar waveform shapes and so we aren’t capturing this drift correctly as the spike sorting didn’t work correctly and these neurons were assigned the same label. To respond to these questions, we chose to perform dimensionality reduction on the waveforms of each neuron and visualize the evolution over time of all the recorded spikes (Fig. 4d &amp; Fig. 6a). <a href="https://pair-code.github.io/understanding-umap/">UMAP</a> performs the dimensionality reduction by building a high-dimensional graph representation of the data and optimizing an objective leading to a lower-dimensional graph which is structurally similar to the first one. In the context of this paper, the lower-dimensional representation is an unbiased way of selecting “features” (UMAP dimensions) which will allow us to quantify how the signal changes over time. Once again, we observed very stable clusters suggesting minimal electrode drift.</p>

<h4 id="tracking-age-associated-single-unit-waveform-changes">Tracking age-associated single-unit waveform changes</h4>
<p>You may be thinking, great, we have a stable BMI but what’s the point? Well in this part of the paper we provided one of the many types of analysis this technology enables. We observed slow age-related neuron electrophysiological change. Although this analysis was fairly rudimentary (based on PCA and ‘pseudotime’ analysis, a framework taken from the single-cell community), it shows how stable BMIs can be leveraged to study long-term changes in brain activity. Ultimately, it would be great to see this techonology used to study development &amp; learning, neurodegeneration and age-related cognitive decline.</p>

<h2 id="conclusion">Conclusion</h2>
<p>There is still a fair amount of work to do to democratize access to this technology and make sure it’s safe to use in other animals and humans. The results presented in this paper suggest that the effort might be worthwile as having more stable BMIs can help answer questions related to aging-related neuronal degradation and the electrical signatures associated to various pathologies. This is a very exciting area of research which I am happy to have been a (minor) part of!</p>

<h2 id="miscellaneous-links">Miscellaneous Links</h2>
<ul>
  <li><a href="https://axoft.us/">Axoft</a>: a company spun-out of the Liu lab by Paul LeFloch working on getting similar interfaces closer to clinical applications</li>
  <li><a href="https://www.nature.com/articles/s41928-022-00913-9">Review</a> (linked to above) going over some of the main trends in flexible electronics</li>
  <li><a href="https://www.science.org/doi/10.1126/science.abf4588">Neuropixel 2.0</a>: one of the most used current rigid BMIs</li>
  <li><a href="https://neuralink.com/approach/">Neuralink</a>: Musk’s company trying to build commercial BMIs</li>
</ul>]]></content><author><name></name></author><category term="math" /><category term="bioengineering" /><category term="code" /><category term="papers" /><summary type="html"><![CDATA[Flexible mesh electronics for lifetime neuron recordings in mice]]></summary></entry><entry><title type="html">Why We Sleep, Matthew Walker</title><link href="http://localhost:4000/blog/2022/book-review-why-we-sleep/" rel="alternate" type="text/html" title="Why We Sleep, Matthew Walker" /><published>2022-01-16T16:12:00+01:00</published><updated>2022-01-16T16:12:00+01:00</updated><id>http://localhost:4000/blog/2022/book-review-why-we-sleep</id><content type="html" xml:base="http://localhost:4000/blog/2022/book-review-why-we-sleep/"><![CDATA[<h1 id="2022-a-year-for-better-sleep">2022, a year for better sleep</h1>

<p>What better way to start the new year than get better at laying still, in bed, with your eyes closed? Although I must have read Why We Sleep around six months ago, it seems appropriate to write about some of the main things I learned thanks to this book. In it, Matthew Walker tackles all we need to know about sleep: what it is (with a particular focus on dreams), why we do it and how to become better sleepers on personal and societal levels. He does so quite skillfully, easing the reader through various concepts while giving them a framework to aid in thinking about sleep. Personally, I find it great that world experts such as Matthew Walker write these didactic books, although it always leaves me with a never ending list of papers and references to work through …</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-6 mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/calvin_hobbes_sleep.jpg" alt="" title="Calvin and Hobbes fast asleep" width="400" height="300" />
    </div>
    <div class="col-sm-6 mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/why_we_sleep_book_cover.jpg" alt="" title="Why We Sleep book cover" width="300" height="300" />
    </div>
</div>
<div class="caption">
    Aim to sleep as deeply as Hobbes and dream as wildly as Calvin. 
</div>

<h1 id="key-takeaways">Key Takeaways</h1>

<ul>
  <li>What is sleep ? According to <a href="https://www.nature.com/subjects/sleep">nature</a>, sleep is “a state characterized by a reduced responsiveness to sensory stimuli, suppressed locomotor activity and rapid reversibility to wakefulness. It is a process that is evolutionarily conserved in the majority of organisms from worms to humans. In humans it has four stages, each with characteristic and distinctive electroencephalographic (EEG) signatures.” Walker gives pretty much the same definition, explaining that sleep is observed all across the animal kingdom as well as delving into the separate stage of sleep including REM (rapid eye-movement - it’s main function is integration of information into existing neuronal networks) and NREM (non REM - it’s main function is reflection).</li>
  <li>Do I <em>really</em> need to sleep ? Unequivocally, yes. Sleep is instrumental in building memories, physical recuperation, creativity, attention &amp; focus, lifespan (all forms of major diseases, cancer, heart disease, dementia, etc. have recognized causal links to a lack of sleep), being emotionally regulated, having a strong immune system,… Adequate sleep is the <strong>pillar</strong> to having a healthy body and mind. Of course you should eat well, exercise often, and be intellectually stimulated buuuut you will see drastically reduced benefits to these lifestyle choices if you’re not sleeping enough.</li>
  <li>How do I get better at it ?
    <ul>
      <li>Stick to a sleep schedule (most important! Even on weekends, as mush as possible.)</li>
      <li>Exercise is great, but not too late in the day. Try to exercise at least thirty minutes on most days but not later than two to three hours before your bedtime.</li>
      <li>Avoid caffeine and nicotine.</li>
      <li>Avoid alcoholic drinks before bed.</li>
      <li>Avoid large meals and beverages late at night.</li>
      <li>If possible, avoid medicines that delay or disrupt your sleep.</li>
      <li>Don’t take naps after 3 p.m.</li>
      <li>Relax before bed. Don’t overschedule your day so that no time is left for unwinding. A relaxing activity, such as reading or listening to music, should be part of your bedtime ritual.</li>
      <li>Take a hot bath before bed.</li>
      <li>Dark bedroom, cool bedroom, gadget-free bedroom.</li>
      <li>Have the right sunlight exposure. Daylight is key to regulating daily sleep patterns. Try to get outside in natural sunlight for at least thirty minutes each day. If possible, wake up with the sun or use very bright lights in the morning.</li>
      <li>Don’t lie in bed awake.</li>
    </ul>
  </li>
  <li>But I need to get up early for work… Indeed, one of the most interesting things I took away from this book is how society has been built around the sleep schedule of early-birds. This is nonsensical, especially for teenagers who need to wake up early to go to school - their chronotypes have naturally shifted towards a later wakeup and bed time. Some professions require stringent schedules that go late into the night (such as medical residencies) and are therefore harmful to anyone forced to stick to them.</li>
  <li>Drop the nightcap and the (unprescribed) sleeping pills. Alcohol is a sedative, it makes you unconscious which is a state quite different from sleep. Sleeping pills have harmful side effects, are poorly dosed and don’t actually induce sleep in its most natural and reparative form.</li>
  <li>Not sleeping enough kills, not only due to the myriad of health reasons mentioned above, but also because drowsy driving is far more common (and equally deadly) than drunk driving.</li>
  <li>What about my coffee? Fascinatingly, your brain releases a chemical called Adenosine which builds up throughout the day and acts as a form of sleep pressure. The more you have, the more you want to sleep. Caffeine works by essentially battling adenosine for the limited number of spaces on adenosine receptors. Coffee is basically helping you block out the sleepiness signal which is produced by your brain and it’s half-life in your body is around six hours, meaning you really shouldn’t be taking any after lunch. Of course, this is subject to inter-person variability but interesting nonetheless. Also, be careful of dark chocolate which can contain as much caffeine as a quarter cup of espresso!</li>
</ul>

<p>I should note, however, that <a href="https://guzey.com/books/why-we-sleep/">some</a> have disagreed with a number of claims Matthew Walker makes. Frankly, I’m pretty aligned with what some have commented <a href="https://news.ycombinator.com/item?id=21546850">here</a>, I’m sure there are certain factual inaccuracies in the book but that isn’t what I’ve taken away from the book. It serves as a nice introduction to some of the science behind sleep and provides actionable information to try and get your sleep under control.</p>

<h1 id="conclusion">Conclusion</h1>

<p>I intuitively learnt about the value of sleep during my “prépa” days. During those two years of intensive preparation prior to the French national selection exams, you needed to optimize as much as you could to be immensely productive. At first, I would stay up later trying to finish whatever math exercise had tripped me up. Quite quickly, and thanks to the advice of teachers and academic staff, I realized that sleep was an absolute non-negociable if I wanted to remember anything of what I had been studying a few weeks ahead of time. Although I was far from perfect at scheduling in enough sleep, I progressively got better at sticking to a consistent schedule which was incredibly helpful in the long run. Why we Sleep has given me the adequate scientific background to understand what I had caught onto during those years. Whether you struggle with managing your sleep or are just generally interested in the topic - go ahead and read this book! You definitely won’t regret it.</p>]]></content><author><name></name></author><category term="books" /><category term="health" /><summary type="html"><![CDATA[Unlocking the power of sleep and dreams]]></summary></entry><entry><title type="html">BMI (hardware) review</title><link href="http://localhost:4000/blog/2021/BMI-techonology-review/" rel="alternate" type="text/html" title="BMI (hardware) review" /><published>2021-08-21T17:12:00+02:00</published><updated>2021-08-21T17:12:00+02:00</updated><id>http://localhost:4000/blog/2021/BMI-techonology-review</id><content type="html" xml:base="http://localhost:4000/blog/2021/BMI-techonology-review/"><![CDATA[<h1 id="introduction">Introduction</h1>

<p>You may have heard of brain-machine interfaces (or brain-computer interfaces) thanks to the very public announcements made by companies such as <a href="https://neuralink.com/">Neuralink</a>. Very much in accordance with Musk’s strategy of publicly decrying outlandish future achievements to realize on an impossible timescale, he has made some fairly awesome claims for Neuralink’s future. These include, for example, ending the need for verbal communication within 5-10 years. Although these claims will probably take longer to come to fruition, if they ever come at all, they highlight the exciting potential of this truly transformative technology.</p>

<p>The aim of this post is to quickly review what has already been achieved in the field of BMIs, separate the grounded from the fantastic and provide a general scope of what is being achieved in this field.</p>

<h1 id="what-are-they">What are they?</h1>
<p>My old friend <a href="https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface">Wikipedia</a> tells me a BMI is a “direct communication pathway between an enhanced or wired brain and an external device.” It seems this definition is intentionally quite broad. Indeed, a direct communication pathway can mean many things. The word direct in itself is subject to interpretation, how direct is a non-invasive interface like <a href="https://www.cnbc.com/2019/09/23/facebook-announces-acquisition-of-brain-computing-start-up-ctrl-labs.html">the one developped</a> by (formerly known as) CTRL-Labs and now part of <a href="https://tech.fb.com/ar-vr/">Facebook Reality Labs</a> which is non-invasive and worn on the arm? Don’t get me wrong, this tech is frickin’ cool, but it just goes to show that ‘direct’ can be loosened a little. Furthermore, a communication pathway can allow for many different communication protocols, can be one-way or both and if we consider neuroimaging techniques such as fMRI scanners to be BCIs, the so-called pathway can be highly non-portable and burdensome. <strong>I’ll focus here on BCI technologies using electrical activity</strong> generated by the brain or the muscular system rather than other potential BCI modalities using magnetic fields, absorption spectra of near-infrared light, or blood flow. I will, therefore, willingly restrict my analysis to technologies fitting the definition given by <a href="https://www.nature.com/subjects/brain-machine-interface">nature</a>: “A BMI is a device that translates neuronal information into commands capable of controlling external software or hardware such as a computer or robotic arm.”  Going by said definition, the BMI should be able to (i) record neuronal information and (ii) translate it. This naturally distinguishes the ‘hardware’ i.e the recording technology, from the ‘software’ i.e the processing and decoding algorithms making sense of the captured signals. The software side of things will (if I ever get to it) be the subject of a later post as this is the fascinating algorithmic aspect of BMIs.</p>

<p>From my limited knowledge on the topic, technology capable of doing what is mentioned above usually involves tracking electrical activity generated by ensembles of cortical neurons or the musculo-nervous system. These can be separated into two broad categories. The first is invasive BCIs, that is they require implantation of some part of the device directly into the brain. Invasive technologies could further be broken down between single site recordings and multi-site recordings if we really want to push the nomenclature further. The second overarching type is, <em>you guessed it</em>, non-invasive BCIs. For those of you who feel a little uneasy about having a foreign body implanted directly into your brain tissue, you may be happy that more than a few researchers and companies are working on the second approach. Personally, I don’t really see the problem with the former, provided the safety, efficacy and usefulness have all been tried and tested.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-6 mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/neuralink_bmi.jpg" alt="" title="neuralink bmi" width="400" height="300" />
    </div>
    <div class="col-sm-6 mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/utah_array_bmi.png" alt="" title="utah array bmi" width="300" height="300" />
    </div>
</div>
<div class="caption">
    Neuralink's BMI device on the left, the widely popular Utah Intracortical Electrode Array on the right
</div>

<h1 id="past-developments">Past developments</h1>
<p>As one might expect, the development of BMIs is intimately linked with progress in the larger field of neuroscience. It was not always obvious that the brain might be this big electrical machine, so any direct means of interfacing was impossible without some comprehension of the basic mechanisms involved. Thankfully, by the late 1700s the Italian scientist Luigi Galvani revealed the electrical nature of neurophysiology and opened the way to generations of neurophysiologists who have improved our understanding of the nervous system and developed various electrode technologies. To start recording the brain, it was necessary to understand that there were underlying signals that might contain useful information.</p>

<p>Once this was understood, as illustrated in <a class="citation" href="#hong_novel_2019">(Hong &amp; Lieber, 2019)</a>, the number of simultaneously recorded neurons by implantable electrodes approximately doubled every 7 years since the 1970s. This pursuit of scalability in neural recordings came from the (fairly reasonable) belief that acquiring more neuron signals in a robust manor would increase BMI usability and performance provided the decoding algorithms keep up. Of course, many challenges stood (and stand) in the way of ever-increasing neuron tracking. According to the authors, this relatively (when compared to Moore’s law) slow exponential increase is due to three factors that make the scaling difficult. The first is that increasing electrode count without inducing extra tissue damage is difficult, the second is that designing lightweight I/O interfaces capable of handling thousands of electrodes remains a challenge and finally, scaling the electrodes themselves isn’t straightforward as electrode impedance and thermal noise need to be kept within reasonable boundaries. The combination of these challenges explains the slow rise of the number of neurons recorded by electrophysiological recordings at the single-neuron level and gives a good overview of the direction of past research efforts. If each of these technical challenges is further addressed and if past trends are to be believed and used for extrapolation (a <em>skeptical empiricist</em> might argue quite the contrary - yes, I’m in the middle of reading Taleb’s Black Swan) then future discoveries will slowly but surely increase the number of recorded neurons by chipping away at these difficulties. So, what does all of this look like - concretely - in terms of recording devices ? The actual recording technologies (hardware) used to perform these recordings has evolved from Tungsten microwire electrodes, to Silicon probes to Tetrodes, each step addressing the concerns raised above.</p>

<h1 id="current-state-of-the-art">Current State of the Art</h1>
<p>Going back to non-invasive BMIs, a few prominent examples include Facebook’s Reality Labs (former CTRL-Labs) wristband or the Kernel headmount. Although at the time of writing it doesn’t seem Facebook has done much with their technology, it supposedly relies on capturing the electrical signals directly from the wrist to control an external device. Aside from the obvious non-invasive advantages, this will always be limited in the scope of possible applications. Signals travelling down to the wrist are already fairly specific, using them can make for some neat demos but doesn’t perhaps qualify as inspirational science. The headmount created by <a href="https://www.kernel.com/">kernel</a>, which I discovered on Lex Fridman’s podcast, seems to hold a little more promise when thinking about the non-invasive direction. According to the website, Kernel Flow is a non-invasive, full-coverage, optical headset that gives precise measures of brain activity. Crudely, it throws photons at your brain and analyzes how they scatter to infer what is going on inside. As it has not been tested clinically, we need to be cautiously optimistic about what this kind of tech might bring as it is still very much in the realm of experimental science.</p>

<p>The SoA in invasive BMIs is changing rapidly and quite exciting. I have personally worked with some ultrasoft mesh nanoelectronics which have a range of properties making them good candidates for the next generation of invasive technologies. This is in the same pursuit of scalability and durability that has marked the historical developments of BMIs. Be sure to go over to the publications page to check that out ;). There is also <a href="https://neuralink.com/approach/">Neuralink’s system</a> which can supposedly track thousands of neurons and uses soft, precisely placed flexible threads. Given the number of neurons in the brain (~100 billion) this still seems to fall short of what we would need to gain system-wide understanding and tracking but is nonetheless exciting.</p>

<p>Ultimately, although we have already been able to achieve remarkable milestones, <a class="citation" href="#anumanchipalli_speech_2019">(Anumanchipalli et al., 2019)</a>, <a class="citation" href="#willett_high-performance_2021">(Willett et al., 2021)</a>) in BMI development thanks to fixed arrays, the future seems to lie within these softer, denser technologies which will need to be accompanied by more scalable decoding algorithms.</p>

<h1 id="references">References</h1>
<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="hong_novel_2019" class="col-sm-8">
    
      <div class="title">Novel electrode technologies for neural recordings</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Hong, Guosong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lieber, Charles M.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="anumanchipalli_speech_2019" class="col-sm-8">
    
      <div class="title">Speech synthesis from neural decoding of spoken sentences</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Anumanchipalli, Gopala K.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chartier, Josh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Chang, Edward F.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Nature</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="willett_high-performance_2021" class="col-sm-8">
    
      <div class="title">High-performance brain-to-text communication via handwriting</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Willett, Francis R.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Avansino, Donald T.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hochberg, Leigh R.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Henderson, Jaimie M.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Shenoy, Krishna V.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Nature</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>]]></content><author><name></name></author><category term="bioengineering" /><category term="papers" /><summary type="html"><![CDATA[A minimalist review of Brain Machine Interface (BMI) technology]]></summary></entry><entry><title type="html">Lifespan, David Sinclair</title><link href="http://localhost:4000/blog/2021/book-review-lifespan/" rel="alternate" type="text/html" title="Lifespan, David Sinclair" /><published>2021-04-25T17:12:00+02:00</published><updated>2021-04-25T17:12:00+02:00</updated><id>http://localhost:4000/blog/2021/book-review-lifespan</id><content type="html" xml:base="http://localhost:4000/blog/2021/book-review-lifespan/"><![CDATA[<h1 id="its-a-good-book-">It’s a good book …</h1>
<p>If you enjoy thinking about possible futures and indulging in science fiction you may have come across the idea that, one day, science will help us venture beyond our biological barriers and extend our lifespans indefinitely. While David Sinclair doesn’t seem to suggest this will happen just yet (contrary to some more <a href="https://www.businessinsider.com/googles-chief-futurist-thinks-we-could-start-living-forever-by-2029-2016-4?IR=T">outspoken residents</a> of Silicon Valley), his book Lifespan, Why we Age and Why We Don’t Have To, elegantly introduces the reader to his information theory of aging and what we may do to be able to slow it down before eventually getting rid of this <strong>disease</strong> altogether. And yes, it is Dr. Sinclair’s view that aging is a disease and should be treated as such, which I’ll get into below. He also covers a host of ethical and societal considerations throughout the book whilst summarizing a lot of the <a href="https://sinclair.hms.harvard.edu/people/david-sinclair">research</a> he has conducted over the past years. Personally, I read the book adamantly and it has inspired me to read more about the field of aging keep up to date with the research in the field.</p>
<div class="row justify-content-sm-center">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lifespan.jpg" alt="" title="example image" width="200" height="400" />
</div>
<div class="caption">
    Wow, a book cover! (On an unrelated note his book cover looks like a plot in seaborn... maybe I should spend less time looking at jupyter notebooks)
</div>

<h1 id="aging-is-a-disease">Aging is a disease</h1>
<p>Of course, I am highly biased as I’ve read the book and am quite enthusiastic about a lot of what our Australian professor writes about, but doesn’t this idea that aging should be considered a disease -in itself- just seem so obvious? As we age, our entire body slowly and painfully grinds to a halt. Surely this is a disease. But so why don’t we consider it as such? I should note that at this stage you can do us both a favor and throw the “it’s natural, it’s not a disease” blabla back to wherever this astoundingly ridiculous concept comes from. The day you are, god forbid, diagnosed with any kind of illness I should hope your doctor doesn’t respond to you by saying, just accept it bro, it’s natural. Diseases are “natural”, to take the definition literally: they occur in nature, and so does aging. Unfortunately for us, it seems Nature doesn’t really care if we live or die, so I’d rather go the non-natural way and trust medicine/research based on solid science. However, some scientist and doctors <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4037311/">don’t seem to think</a> it’s such a good idea either to consider aging a disease. I won’t go into the semantic implications of calling aging a disease covered in the link, but it seems the disagreement is rather superficial. It’s also worth mentioning, that these considerations are inconsequential compared to the increase in funding calling aging a disease could bring to the field and all the potential breakthroughs that might arise thereafter. If, as Sinclair writes, there is an exponential increase in other diseases such as cancer, cardiovascular illness, diabetes, dementia, stroke etc.. as each year passes after the age of 20, I’ll call aging whatever you want just so that it receives more funding. Trying to address the root cause of all these problems rather than investing <em>all</em> our efforts into treating the individual diseases listed seems to be a more efficient use of time and money.</p>

<h1 id="how-does-it-work">How does it work?</h1>
<p>I won’t pretend I’ve truly digested all the content in the book regarding the mechanisms at play but I’ll try to give a TL;DR version nonetheless (in terms I can understand without having to do some good old-fashioned copying). And I should note that perhaps it’s because I’m a little more math oriented but I find the Information Theory aspects of this book’s explanation of aging particularly clear and fascinating, so that may transpire in this account.</p>

<p>According to the author, aging is quite simply a loss of epigenetic information over time. (The epigenome is essentially the whole machinery around your DNA which allows different genes to be switched on or off and controls levels of expression). The analogy from the book I find most poignant is that of the DVD player. DNA is discrete, digital information that is stored within each of our cells, and this is what we can call the DVD. Then comes the epigenome which reads and makes sense of the digital information, it is the DVD player, and it stores its information in an analog format. Rather, it converts the digital data to analog as it reads genes which are stored digitally but regulates gene expression levels which are continuous variables. This is precisely where aging occurs, accumulation of epigenetic noise means the information content of the analog data doesn’t hold over time, our reader can’t seem to make sure the right genes are expressed at the right level. Of course, scratches on the DVD (or small breaks and alteration in DNA) represent damage to the digital data, but the problem is more that these scratches can impair the whole analog reading mechanism even if they occur at places we wouldn’t deem important. Think of a scratch during the opening credits of a movie making the whole thing not work. Of course, there are many more intricacies to this theory I won’t delve into, and regardless of whether it is actually true or not (experimental results on yeast and mice suggest it is), isn’t it elegant? It remains a philosophical debate whether the simplicity and elegance of a scientific theory hold any predictive powers as to its veracity, but setting this aside I think it’s possible to simply admire an elegant theory for its own sake. Of course, Sinclair et. al would perhaps rather go into what exactly this information theory of aging means to those who want to solve it.</p>

<h1 id="can-we-slow-and-reverse-it">Can we slow and reverse it?</h1>
<p>Now that we have a very basic understanding of the process in itself, the question naturally arises as to what the best course of action is to try and preserve as much epigenetic information as we can. Drawing once again from <a href="http://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">Shannon’s A Mathematical Theory of Communication</a> paper, the book suggests that we should find the biological equivalents to the components of the transmission system presented in the paper designed to recover lost information.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/claude_shannon_correction_system.png" alt="" title="example image" width="800" height="400" />
    </div>
</div>
<div class="caption">
    The transmission system to implement in our own bodies shown in Lifespan and taken from Shannon's paper 
</div>

<p>Creating a similar system in our own bodies could be a solution to this loss of epigenetic information. (Side note: cf. the paper but it seems ergodicity is everywhere and not just this blog!) Although, unfortunately, theoretical considerations around actual information theory such as, channel and noise entropy or transmission capacity of the biological channels considered here, remain fairly shallow in the book, Sinclair goes deep into the biology of the possible “correcting device”. There seems to be a set of genes that are good potential candidates for the correcting device that have been used to restore cellular identity and Sinclair’s lab is actively working on making this an implementable reality for humans. The possibilities for delivering these genes and activating them are numerous but the important thing is that you could switch them on and off and control the process of cellular rejuvenescence quite precisely. It remains a mystery and is therefore an area of active research as to who might be the observer and how they might be obtaining source and receiver information before supplyng correction data. Of course, aside from actually reversing aging through these correcting genes there are other possible solutions to the problem of aging. The book highlights three, what are referred to as, “longevity pathways”. These pathways engage survival mechanisms in the body and activating them has been shown to extend healthy lifespans of mice and other species in the lab. The interesting thing for us readers and possible consumers, is that one can ingest molecules such as <a href="https://www.nmn.com/topic">NMN</a> that are precursors to NAD.</p>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/NMN.png" alt="" title="example image" />
    </div>
</div>
<div class="caption">
    NMN, for the chemists among you
</div>

<p>Check the link or the book for more detailed explanations on exactly how this works and why NAD is such an important molecule for our bodies, but the cool thing is, it’s a fairly straightforward first step in the battle against aging. This is probably the right time to note that, these and other methods that are currently being worked out will likely only <strong>supplement</strong> an already healthy lifestyle. If you’re chronically overweight, never do sports and frequently overeat, or smoke, or do a host of other things that are terrible for our bodies, that’s probably where you should start in the battle against aging.</p>

<h1 id="just-give-me-the-pills-and-what-i-should-do-on-a-daily-basis">Just give me the pills and what I should do on a daily basis</h1>
<p>Do you want to live forever? Then buy these pills which you can find at the following link https://sebastianpartarrieu_pills_to_make_you_sexy_and_live_forever, of course completely unafilliated to the present blog. A little more seriously, Sinclair shares in the book what he takes on a daily basis and some habits that can help live a longer, healthier, life. As he mentions, this has not been subject to rigorous long-term clinical trials and is therefore definitely not medical advice. It’s more personal experimentation than solid science for the moment, but here goes:</p>
<ul>
  <li>1 gram of NMN every morning with 1 gram of reseveratrol and 1 gram of metformin</li>
  <li>Daily dose of vitamins D, \(K_2\) and 83 mg of aspirin</li>
  <li>Keeping carbs low</li>
  <li>Skiping one meal a day</li>
  <li>Blood analysis every couple of months to analyze dozens of biomarkers</li>
  <li>Walking/sports as a daily habit with some temperature stress thrown in there</li>
  <li>No smoking, no microwaved plastics, no excessive UV exposure, X-rays or CT scans</li>
  <li>Cool side for sleeping (check out an upcoming blog plost on Matthew Walker’s Why We Sleep to understand why this is important) and during the day</li>
  <li>Body weight kept in optimal range for healthspan</li>
</ul>

<p>To be honest, a lot of these are nothing more than common sense or at least have been generally accepted for years now. Personally, I manage to do everything on the list fairly easily apart from the pills and vitamin supplements as well as the frequent blood analysis. Being just 21 I figure I can focus on building healthy durable habits in my 20s and start seriously looking into supplements and blood analysis in a decade or so, even though I think monitoring one’s health proactively with all the technologies available to us now is a must. Hopefully, results from all the clinical trials being conducted on whether these substances are beneficial for extending the healthspan of humans will have yielded results by the time I need to start taking them.</p>

<h1 id="somewhat-related---proactive-healthcare">Somewhat related - proactive healthcare</h1>

<p>This is a topic I’d also like to delve further into in a future blog post but as the book touches upon this I might as well give my two cents on the matter. Proactive healthcare is the simple idea that we should be, yes, proactive rather than reactive when it comes to our health. It is much easier to take the correct steps to ensure disease doesn’t occur in the first place rather than have to deal with it when it comes. Achieving proactive healthcare requires some effort from the part of the individual, no doubt. Following some of the more basic steps we discussed above is a good start. Even better is putting in place monitoring systems that alert us before any potential problems arise in our bodies. This works by first tracking relevant data produced by our bodies before making sense of it and gaining an overall sense of our health across a given period of time. The possible data is plentiful and includes biomarkers in our blood as has been mentioned above but also simply relevant signals such as heart rate which can be tracked with a smart watch or any other kind of wearable smart device boasting the appropriate sensors. 
Doesn’t it just seem outrageous that concepts of predictive maintenance and prognostics health management are readily applied in industrial settings but we globally fail to do so with our own bodies? Of course, a spinning turbine has less moving parts and is therefore quite a lot easier to diagnose than a human being, yet, the fundamental idea that treating problems only after they arise is terribly illogical and inefficient bridges the gap between factories and bodies. Ideally, in the near future we will all have access to personalized AI health assistants that use all the data extracted from our bodies to give us daily recommendations and feedback on our current health status. All of this is pretty nifty if you ask me, I’ll be sure to follow the developments of personalized and proactive healthcare in the years to come. Finally, solving aging is perhaps the ultimate proactive stance when it comes to healthcare, as aging is <em>the</em> risk factor of most deadly diseases.</p>

<h1 id="clinical-trials-to-follow-in-the-near-future--miscellaneous-links">Clinical trials to follow in the near future &amp; miscellaneous links</h1>

<p>Here are a few links to clinical trials on humans to follow over the next few months and years that should help in evaluating whether the results presented in the book on yeast and mice hold for humans as well:</p>
<ul>
  <li><a href="https://clinicaltrials.gov/ct2/show/NCT04823260">To Evaluate the Efficacy and Safety of NMN as an Anti-ageing Supplement in Middle Aged and Older (40-65 Years) Adults</a></li>
  <li><a href="https://clinicaltrials.gov/ct2/show/results/NCT02432287">Metformin in Longevity Study (MILES). (MILES)</a></li>
</ul>

<p>I seem to have found as many links explaining why designing these clinical trials is hard:</p>
<ul>
  <li><a href="https://pubmed.ncbi.nlm.nih.gov/28364543/">Clinical Trials Targeting Aging and Age-Related Multimorbidity </a></li>
  <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5055653/">Strategies and Challenges in Clinical Trials Targeting Human Aging</a></li>
</ul>

<p>(EDIT, thanks Phil!): some more links for interesting podcasts and surrounding information</p>
<ul>
  <li>Peter Attia’s podcast, the drive, <a href="https://www.youtube.com/watch?v=edrIEC0kJv8">round #1</a></li>
  <li>Peter Attia’s podcast, the drive, <a href="https://www.youtube.com/watch?v=IgosGWLVUrU">round #2</a></li>
  <li>There are plenty of study in mice, some of which are regrouped under the <a href="https://www.nia.nih.gov/research/dab/interventions-testing-program-itp">Interventions Testing Program</a>, sponsored by the National Institute on Aging</li>
</ul>

<h1 id="conclusion">Conclusion</h1>

<p>I hope you managed to get through this without a yawn and I <em>sincerely</em> recommend that you read this book. I not only learnt a lot by reading it but it has also shifted my perspective on something I thought was the realm of science fiction. Scientists like David Sinclair are truly a source of inspiration as they work tirelessly in the face of these monumental questions to bring knowledge forward, one step at a time. I look forward to observing how these theories grow over time.</p>]]></content><author><name></name></author><category term="books" /><summary type="html"><![CDATA[Rethinking aging]]></summary></entry><entry><title type="html">Starting a blog</title><link href="http://localhost:4000/blog/2021/starting-blog/" rel="alternate" type="text/html" title="Starting a blog" /><published>2021-03-13T16:12:00+01:00</published><updated>2021-03-13T16:12:00+01:00</updated><id>http://localhost:4000/blog/2021/starting-blog</id><content type="html" xml:base="http://localhost:4000/blog/2021/starting-blog/"><![CDATA[<p><em>Note: originally, the blog was called Ergodicity in Thought.</em></p>

<p>Hey there, I hope you’re doing well :smile:.</p>

<p>I’m not entirely sure why you’re reading this (or why I’m writing this), but I’ll try and convince both of us that it’s worthwhile. If it’s not, I guess I could say you can find comfort in the idea it took me longer to write than you to read. <em>Yet</em> the whole point of these few lines will be to formalize the intuition that structuring one’s thoughts and taking time to express them has intrinsic value.</p>

<p>So why the blog and why that somewhat pompous title?</p>

<p>The reason for starting the blog is hidden in the title so let’s begin with that: <em>Ergodicity in Thought</em>. I first came across <a href="https://en.wikipedia.org/wiki/Ergodic_theory">ergodic systems</a> in a Statistical Physics class @ Mines ParisTech. For those who haven’t, this is (very roughly and with as little formalism as possible) what it means:</p>

<p>Say you have a system made up of N ‘things’ (probably particles, let’s be honest). Each of these N particles can take on a certain number of states, let’s call that number P. So if we can tell the N particles apart from each other, we have <em>drumroll</em> \(P^N\) number of, what we call, micro states. This is just the total number of configurations of our system, if we’re looking individually at what particle is in what state. Knowing the system’s micro state means knowing exactly what particles are doing what and odds are this doesn’t hold as soon as your system has a large number of them… Yet, we can still want to measure things about the system, it’s just we’re measuring macroscopic observables that are a sum of individual contributions of particles, each living its own life within the confines of our P possible states.</p>

<p>Ok, you might be wondering, but where on earth does ergodicity come in? Well, firstly it sounds fancy and <a href="https://mathoverflow.net/questions/403036/john-von-neumanns-remark-on-entropy">like entropy</a> I hope the mystery of it all will give me an advantage in any future debate. Second, let’s measure a macroscopic observable of our system, say it’s temperature. For ergodic systems this macroscopic observable can be calculated by taking an average over a certain amount of time or over the number of possible micro states. This means that the temperature we’re measuring over a period of time (short for us but very long in terms of micro state transitions for the system) is equal to the amount we could calculate at one fixed point in time by averaging over the possible micro states.</p>

<p>After this long detour you might understand what I’m getting at. Essentially, I’d like to think that my very own thought process, the ergodic system, can produce an observable, this blog, which will give over time an equivalent result to a blog produced by averaging over the space of ideas. Basically, I’d like these posts to explore many different ideas and hopefully let me enjoy myself along the way. There’s probably a few flaws in the analogy but I liked the sound of the title and it announces forthwith the color of this blog - a mix of random explorations containing book &amp; paper reviews, discussions on daily habits such as meditation &amp; intermittent fasting, brief overviews of topics such as the climate crisis with, of course, some technical mathy posts here and there to keep it spicy.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Blogs and weird titles, why go through the hassle?]]></summary></entry></feed>